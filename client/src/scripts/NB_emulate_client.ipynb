{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f239c240",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import os\n",
    "\n",
    "from emulate_client import *\n",
    "\n",
    "print(f\"CONFIG FILE {CONFIGS_DIR}\")\n",
    "CIANNA_OTF_DIR = \"/home/gsainton/01_CODES/CIANNA_OTF/CODE\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3777285",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\"\"\"\n",
    "Main function for the client.\n",
    "\n",
    "Steps:\n",
    "    - Load the client configuration.\n",
    "    - If a remote connection is specified, establish an SSH tunnel.\n",
    "    - Update the local CIAnna models XML file by always retrieving the \n",
    "            latest version.\n",
    "    - Locate FITS images from the designated input folder.\n",
    "    - Emulate a set number of client requests to the server.\n",
    "\n",
    "Note:\n",
    "    - Vérifier sur le fichier FITS est compatible avec le modèle YOLO.\n",
    "\"\"\"\n",
    "# Load configuration from JSON file\n",
    "print(CONFIGS_DIR)\n",
    "config = load_config(os.path.join(CONFIGS_DIR,\"param_cianna_rts_client.json\"))\n",
    "\n",
    "# Here is created a directory to save the XML files with the request to server\n",
    "JOB_DIR = os.path.join(CIANNA_OTF_DIR, config.get(\"JOB_DIR\"))\n",
    "os.makedirs(JOB_DIR, exist_ok=True)\n",
    "print(f\"Job directory {JOB_DIR}\")\n",
    "\n",
    "# Path to the local Cianna models XML file\n",
    "local_models_file = config.get(\"LOCAL_FILE_MODELS\")\n",
    "\n",
    "# Determine connection mode and set server URL accordingly.\n",
    "print(40 * \"-.\")\n",
    "client_connexion = config.get(\"CLIENT_CONNEXION\", \"local\").lower()\n",
    "tunnel = None\n",
    "if client_connexion == \"remote\":\n",
    "    print(\"Establishing remote connection via SSH tunnel...\")\n",
    "    tunnel = create_ssh_tunnel(\n",
    "        ssh_server_ip = config.get(\"SSH_SERVER_IP\"),\n",
    "        ssh_username  = config.get(\"SSH_USERNAME\"),\n",
    "        ssh_password  = config.get(\"SSH_PASSWORD\"),\n",
    "        remote_port   = int(config.get(\"REMOTE_PORT\", 5000)),\n",
    "        local_port    = int(config.get(\"LOCAL_PORT\", 5000))\n",
    "    )\n",
    "    server_url = f\"http://127.0.0.1:{tunnel.local_bind_port}\"\n",
    "else:\n",
    "    server_url = f\"http://127.0.0.1:{config.get('LOCAL_PORT', 5000)}\"\n",
    "\n",
    "print(f\"Connecting to a {client_connexion} server...\")\n",
    "print(\"Server URL:\", server_url)\n",
    "print(40 * \"-.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba11e227",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pprint import pprint\n",
    "from uuid import uuid4\n",
    "norm_fct_avail = [\"tanh\", \"power\", \"linear\", \"log\", \"squared\" ,\" squared root\"]\n",
    "img_format_list = [\"full\", \"region\"]\n",
    "min_pix, max_pix = 0.4e-6, 0.4e-4\n",
    "\n",
    "# Update the local Cianna models XML file (always retrieves the latest version)\n",
    "models_url = f\"{server_url}/models/CIANNA_models.xml\"\n",
    "updated_result = update_cianna_models(models_url, local_models_file)\n",
    "if updated_result is None:\n",
    "    print(\"Error updating CIANNA models.\")\n",
    "    if tunnel is not None:\n",
    "        tunnel.stop()\n",
    "    #return\n",
    "\n",
    "# Choices of the uses -> will be selected in a GUI\n",
    "\n",
    "yolo_model_user = \"SDC1_Cornu_2024\"  # Supposed to be selected by the user\n",
    "quant_user      = \"FP32C_FP32A\"    # Supposed to be selected by the user\n",
    "norm_fct_user   =\"tanh, linear\"    # Supposed to be selected by the user\n",
    "user_id = uuid4()\n",
    "# Check to be added in the graphical interface\n",
    "\n",
    "# parse norm_fct_user to check if it is a valid normalization function\n",
    "norm_fct_user = norm_fct_user.split(\",\")\n",
    "norm_fct_user = [fct.strip() for fct in norm_fct_user]\n",
    "if not all(fct in norm_fct_avail for fct in norm_fct_user):\n",
    "    sys.exit(\"One or more normalization functions are not available.\")\n",
    "\n",
    "# remove brackets and spaces in norm_fct_user\n",
    "norm_fct_user = [fct.replace(\"[\", \"\").replace(\"]\", \"\").strip() for fct in norm_fct_user]\n",
    "\n",
    "print(f\"Norm functions selected by the user: {norm_fct_user}\")\n",
    "print(f\"Type of norm_fct_user: {type(norm_fct_user)}\")\n",
    "\n",
    "\n",
    "img_format = \"full\"  # choice between full (the full raw image is sent)\n",
    "                        #            and region (the coordinates are sent)\n",
    "\n",
    "if img_format not in img_format_list:\n",
    "    print(\"Wrong choice of image type \")\n",
    "    sys.exit(\"Wrong choice of image type \") \n",
    "\n",
    "# Check if the image is compatible with the YOLO model\n",
    "model_info = get_model_info(config.get(\"LOCAL_FILE_MODELS\"), yolo_model_user)\n",
    "\n",
    "if model_info is None:\n",
    "    print (40*\"-.\")\n",
    "    print(\"Unknown model, please check the models available.\")\n",
    "    print (40*\"-.\")\n",
    "else:\n",
    "    pprint(model_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dcc1533",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from astropy.io import fits\n",
    "from astropy.wcs import WCS\n",
    "from astropy.visualization import (ZScaleInterval, ImageNormalize)\n",
    "\n",
    "\n",
    "def plot_fits_ra_dec(image_path):\n",
    "    \"\"\"\n",
    "    Plot a FITS image with RA/DEC axes using WCS projection.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    image_path : str\n",
    "        Path to the FITS file.\n",
    "    \"\"\"\n",
    "    if not os.path.exists(image_path):\n",
    "        print(\"FITS file does not exist:\", image_path)\n",
    "        return\n",
    "\n",
    "    with fits.open(image_path) as hdul:\n",
    "        data = hdul[0].data\n",
    "        header = hdul[0].header\n",
    "\n",
    "        # Handle 3D data (assumes shape is (z, y, x))\n",
    "        if data is None:\n",
    "            print(\"No data in FITS file.\")\n",
    "            return\n",
    "        # Auto-squeeze and reduce to 2D\n",
    "        while data.ndim > 2:\n",
    "            data = data[0]\n",
    "\n",
    "        if data.ndim != 2:\n",
    "            print(f\"Cannot plot image with shape {data.shape}\")\n",
    "            return\n",
    "\n",
    "        # Normalize for visualization\n",
    "        norm = ImageNormalize(data, interval=ZScaleInterval())\n",
    "\n",
    "        # Create WCS object and plot\n",
    "        wcs = WCS(header)\n",
    "        if wcs.naxis==4:\n",
    "            wcs = wcs.dropaxis(2).dropaxis(2)\n",
    "\n",
    "        fig = plt.figure(figsize=(8, 6))\n",
    "        ax = fig.add_subplot(111, projection=wcs)\n",
    "        im = ax.imshow(data, origin='lower', cmap='gray', norm=norm)\n",
    "\n",
    "        ax.coords.grid(True, color='white', ls='dotted')\n",
    "        ax.set_xlabel('Right Ascension (J2000)')\n",
    "        ax.set_ylabel('Declination (J2000)')\n",
    "        plt.colorbar(im, ax=ax, orientation='vertical', label='Pixel value')\n",
    "        plt.title(os.path.basename(image_path))\n",
    "        plt.tight_layout()\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71ed8333",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "h   = random.randint(50, 200)\n",
    "w   = random.randint(50, 200)\n",
    "# Get list if images for test\n",
    "image_folder = os.path.expanduser(config.get(\"IMAGE_FOLDER\",\n",
    "                                                \"/home/gsainton/01_CODES/DIR_images\"))\n",
    "\n",
    "print(f\"Looking for images in {image_folder}...\")\n",
    "images = [os.path.join(image_folder, img) for img in os.listdir(image_folder) if img.endswith(\".fits\")]\n",
    "if not images:\n",
    "    print(\"No fits images in \", image_folder)\n",
    "    if tunnel is not None:\n",
    "        tunnel.stop()\n",
    "    #return\n",
    "\n",
    "\n",
    "image_path = random.choice(images)\n",
    "image_info = get_image_dim(image_path)\n",
    "\n",
    "plot_fits_ra_dec(image_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a69b8be",
   "metadata": {},
   "outputs": [],
   "source": [
    "if image_info is None:\n",
    "    print(f\"Error: Unable to read image dimensions from {image_path}.\")\n",
    "    sys.exit(0)\n",
    "image_size = image_info.get('shape', (0, 0))\n",
    "h = image_size[0]\n",
    "w = image_size[1]\n",
    "\n",
    "print(image_size)\n",
    "\n",
    "if image_size[0] < h or image_size[1] < w:\n",
    "    print(f\"Error: Image dimensions {image_size} are smaller than the requested bounding box ({h}, {w}).\")\n",
    "    sys.exit(0)\n",
    "\n",
    "image_coord = image_info.get(\"ra_dec\", (None, None))\n",
    "\n",
    "\n",
    "print(image_info)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22a55c59",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xml.etree.ElementTree as ET\n",
    "from datetime import datetime\n",
    "from xml.sax.saxutils import escape\n",
    "from xml.dom import minidom\n",
    "\n",
    "def create_xml_param(user_id, image_info, image_path, yolo_model,\n",
    "                     quantization, norm_list, min_pix, max_pix,\n",
    "                     model_filename, output_path=None):\n",
    "    \"\"\"\n",
    "    Crée une structure XML contenant les paramètres de la requête qui \n",
    "    sera renvoyée au serveur. Optionnellement sauvegarde dans un fichier.\n",
    "    \"\"\"\n",
    "    def safe(text):\n",
    "        return escape(str(text))\n",
    "\n",
    "    root = ET.Element(\"YOLO_CIANNA\")\n",
    "    \n",
    "    ET.SubElement(root, \"USER_ID\").text = safe(user_id)\n",
    "    ET.SubElement(root, \"Timestamp\").text = datetime.now().isoformat()\n",
    "    \n",
    "    image_elem = ET.SubElement(root, \"Image\")\n",
    "    ET.SubElement(image_elem, \"path\").text = safe(image_path)\n",
    "    ET.SubElement(image_elem, \"RA\").text = safe(image_info.get(\"ra_dec\")[0])\n",
    "    ET.SubElement(image_elem, \"DEC\").text = safe(image_info.get(\"ra_dec\")[1])\n",
    "    ET.SubElement(image_elem, \"H\").text = safe(image_info.get(\"shape\")[0])\n",
    "    ET.SubElement(image_elem, \"W\").text = safe(image_info.get(\"shape\")[1])\n",
    "\n",
    "    yolo_elem = ET.SubElement(root, \"YOLO_Model\")\n",
    "    ET.SubElement(yolo_elem, \"name\").text = safe(yolo_model)\n",
    "    ET.SubElement(yolo_elem, \"filename\").text = safe(model_filename)\n",
    "\n",
    "    preproc_elem = ET.SubElement(root, \"preprocessing\")\n",
    "    ET.SubElement(preproc_elem, \"quantization\").text = safe(quantization)\n",
    "    ET.SubElement(preproc_elem, \"normalisation\").text = safe(norm_list)\n",
    "    ET.SubElement(preproc_elem, \"min_pix\").text = safe(min_pix)\n",
    "    ET.SubElement(preproc_elem, \"max_pix\").text = safe(max_pix)\n",
    "\n",
    "    # Convert to pretty XML\n",
    "    rough_string = ET.tostring(root, encoding=\"utf-8\")\n",
    "    reparsed = minidom.parseString(rough_string)\n",
    "    pretty_xml = reparsed.toprettyxml(indent=\"  \")\n",
    "\n",
    "    # Save if needed\n",
    "    if output_path:\n",
    "        with open(output_path, \"w\", encoding=\"utf-8\") as f:\n",
    "            f.write(pretty_xml)\n",
    "\n",
    "    return pretty_xml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd70ac84",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model_info = get_model_info(config.get(\"LOCAL_FILE_MODELS\"), yolo_model_user)\n",
    "\n",
    "print(f\"[emulate_client_request] Model info: {model_info}\")\n",
    "\n",
    "#emulate_client_request(server_url, image_path, i+1, config)\n",
    "#print(40 * \"-.\")\n",
    "\n",
    "xml_data = create_xml_param(user_id, image_info, image_path, yolo_model_user,\n",
    "                            quant_user, norm_fct_user, min_pix, max_pix,\n",
    "                            model_info.get(\"Name\"))\n",
    "\n",
    "print(xml_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "383368ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "request_number = 1\n",
    "process_id = send_xml_fits_to_server(server_url, xml_data)\n",
    "if process_id is None:\n",
    "    print(f\"[EMULATE] Error sending request {request_number}\")\n",
    "else:\n",
    "    print(f\"[EMULATE] Request {request_number} sent successfully with process ID: {process_id}\")\n",
    "\n",
    "    try:\n",
    "        # Poll for job completion\n",
    "        print(f\"[EMULATE] Polling for job {process_id} completion...\")\n",
    "        if poll_for_completion(server_url, process_id):\n",
    "            print(f\"[EMULATE] Job {process_id} completed successfully.\")\n",
    "            print(f\"[EMULATE] Downloading result for job {process_id}...\")\n",
    "            download_result(server_url, process_id, destination_folder=DESTINATION_FOLDER)\n",
    "            print(f\"[EMULATE] Result for request {request_number} downloaded successfully.\")\n",
    "        else:\n",
    "            print(f\"[EMULATE] Error: Job {process_id} did not complete successfully.\")\n",
    "    except requests.ConnectionError as e:\n",
    "        print(f\"[EMULATE] Network error while polling/downloading: {e}\")\n",
    "    except requests.Timeout as e:\n",
    "        print(f\"[EMULATE] Timeout error: {e}\")\n",
    "    except Exception as e:\n",
    "        print(f\"[EMULATE] Unexpected error: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b814da4d",
   "metadata": {},
   "source": [
    "## Function to test the hardware of the server"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fb2c70e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import xml.etree.ElementTree as ET\n",
    "from xml.dom import minidom\n",
    "from pprint import pprint\n",
    "\n",
    "import torch\n",
    "import pynvml   # Initialize NVML\n",
    "import psutil   # Get system memory info\n",
    "import platform # Get system information\n",
    "import socket   # Get hostname\n",
    "\n",
    "def get_hw_info():\n",
    "    hw_info = {}\n",
    "\n",
    "\n",
    "    hw_info[\"System\"] = {\n",
    "        \"Hostname\": socket.gethostname(),\n",
    "        \"OS\": platform.system(),\n",
    "        \"OS Version\": platform.version(),\n",
    "        \"Platform\": platform.platform(),\n",
    "        \"Architecture\": platform.machine()\n",
    "    }\n",
    "\n",
    "    hw_info['cpu'] = {\n",
    "        'model': platform.processor(),\n",
    "        'cores': psutil.cpu_count(logical=False),\n",
    "        'threads': psutil.cpu_count(logical=True),  # ← utilisé plus loin\n",
    "        'frequency': psutil.cpu_freq().current,\n",
    "        'load': psutil.cpu_percent(interval=1),\n",
    "        'RAM_GB': round(psutil.virtual_memory().total / 1e9, 2)  # ← manquant\n",
    "    }\n",
    "\n",
    "    gpu_info = []\n",
    "    try:\n",
    "        pynvml.nvmlInit()\n",
    "        device_count = pynvml.nvmlDeviceGetCount()\n",
    "        for i in range(device_count):\n",
    "            handle = pynvml.nvmlDeviceGetHandleByIndex(i)\n",
    "            name = pynvml.nvmlDeviceGetName(handle)\n",
    "            memory_info = pynvml.nvmlDeviceGetMemoryInfo(handle)\n",
    "            total_memory = memory_info.total / (1024 ** 2)  # Convert to MB\n",
    "            free_memory = memory_info.free / (1024 ** 2)    # Convert to MB\n",
    "\n",
    "            cap = torch.cuda.get_device_capability(i)\n",
    "            cap_str = f\"{cap[0]}.{cap[1]}\"\n",
    "            support = {\n",
    "                'fp16': torch.cuda.get_device_capability(i)[0] >= 7,\n",
    "                'fp32': True,\n",
    "                'int8': True,\n",
    "                'bfloat16': torch.cuda.get_device_capability(i)[0] >= 8\n",
    "            }\n",
    "\n",
    "            gpu_info.append({\n",
    "                \"index\": i,\n",
    "                \"name\": name,                      # GPU name \n",
    "                \"total_memory\": total_memory,      # Total memory in MB\n",
    "                \"free_memory\": free_memory,        # Free memory in MB\n",
    "                \"compute_capability\": cap_str,     # Compute capability\n",
    "                \"support_data_type\": support       # Supported data types\n",
    "            })\n",
    "        pynvml.nvmlShutdown()\n",
    "\n",
    "    except pynvml.NVMLError as e:\n",
    "        print(f\"Error accessing GPU information: {e}\")\n",
    "        gpu_info = None\n",
    "\n",
    "    hw_info['gpu'] = gpu_info\n",
    "\n",
    "    return hw_info\n",
    "\n",
    "print(\"Hardware Information:\")\n",
    "hw_info = get_hw_info()\n",
    "\n",
    "pprint(hw_info, sort_dicts=False)\n",
    "\n",
    "\n",
    "def save_hardware_to_xml(info, output_path=\"server_hardware_config.xml\"):\n",
    "    root = ET.Element(\"MachineConfig\")\n",
    "\n",
    "    # System metadata\n",
    "    sys_elem = ET.SubElement(root, \"System\")\n",
    "    for key, val in info.get(\"System\", {}).items():\n",
    "        ET.SubElement(sys_elem, key).text = str(val)\n",
    "\n",
    "    # CPU\n",
    "    cpu = info[\"cpu\"]\n",
    "    cpu_elem = ET.SubElement(root, \"CPU\")\n",
    "    ET.SubElement(cpu_elem, \"model\").text = cpu[\"model\"]\n",
    "    ET.SubElement(cpu_elem, \"cores\").text = str(cpu[\"cores\"])\n",
    "    ET.SubElement(cpu_elem, \"threads\").text = str(cpu[\"threads\"])\n",
    "    ET.SubElement(cpu_elem, \"frequency\").text = str(cpu[\"frequency\"])\n",
    "    ET.SubElement(cpu_elem, \"load\").text = str(cpu[\"load\"])\n",
    "\n",
    "    ram_elem = ET.SubElement(cpu_elem, \"RAM\")\n",
    "    ram_elem.set(\"unit\", \"GB\")\n",
    "    ram_elem.text = str(cpu[\"RAM_GB\"])\n",
    "\n",
    "    # GPU\n",
    "    gpus = info[\"gpu\"]\n",
    "    gpu_root = ET.SubElement(root, \"GPU\")\n",
    "    gpu_root.set(\"count\", str(len(gpus)))\n",
    "\n",
    "    for gpu in gpus:\n",
    "        gpu_elem = ET.SubElement(gpu_root, \"GPU\", id=str(gpu[\"index\"]))\n",
    "        ET.SubElement(gpu_elem, \"name\").text = gpu[\"name\"]\n",
    "        \n",
    "        mem_elem = ET.SubElement(gpu_elem, \"memory\")\n",
    "        mem_elem.set(\"unit\", \"MB\")\n",
    "        mem_elem.text = str(round(gpu[\"total_memory\"], 2))\n",
    "        \n",
    "        ET.SubElement(gpu_elem, \"free_memory_MB\").text = str(round(gpu[\"free_memory\"], 2))\n",
    "        ET.SubElement(gpu_elem, \"compute_capability\").text = gpu[\"compute_capability\"]\n",
    "\n",
    "        supports_elem = ET.SubElement(gpu_elem, \"Supports\")\n",
    "        for dtype, supported in gpu[\"support_data_type\"].items():\n",
    "            ET.SubElement(supports_elem, dtype).text = str(supported).lower()\n",
    "\n",
    "    # Pretty formatting\n",
    "    indent_xml(root)\n",
    "    tree = ET.ElementTree(root)\n",
    "    tree.write(output_path, encoding=\"utf-8\", xml_declaration=True)\n",
    "    print(f\"[OK] Hardware configuration saved to: {output_path}\")\n",
    "\n",
    "\n",
    "\n",
    "def indent_xml(elem, level=0):\n",
    "    # Helper function to add indentation for readability\n",
    "    i = \"\\n\" + level * \"  \"\n",
    "    if len(elem):\n",
    "        if not elem.text or not elem.text.strip():\n",
    "            elem.text = i + \"  \"\n",
    "        for child in elem:\n",
    "            indent_xml(child, level + 1)\n",
    "        if not child.tail or not child.tail.strip():\n",
    "            child.tail = i\n",
    "    if level and (not elem.tail or not elem.tail.strip()):\n",
    "        elem.tail = i\n",
    "\n",
    "hw_info = get_hw_info()\n",
    "save_hardware_to_xml(hw_info, output_path=\"server_hardware_config.xml\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ddpm_model",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
